{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data from Google Search console into BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate\n",
    "For authenttication we should create a service account and grant this service account access to the Google Search Console properties that we want to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/webmasters']\n",
    "SERVICE_ACCOUNT_FILE = 'my_key.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = build(\n",
    "    'webmasters',\n",
    "    'v3',\n",
    "    credentials=credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Define the parameters for the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_url = \"https://www.mandmdirect.com\"\n",
    "PROPERTIES = [\"https://www.google.com\",\"https://www.apple.com\"]\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2020-01-01\"\n",
    "BQ_DATASET_NAME = 'test'\n",
    "BQ_TABLE_NAME = 'test_sc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "      'startDate': start_date,\n",
    "      'endDate': end_date,\n",
    "      'dimensions': [\"page\",\"device\",\"query\"], # uneditable to enforce a nice clean dataframe at the end!\n",
    "      'rowLimit': 25000,\n",
    "      'startRow': 0\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the query and get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the request to grab the data\n",
    "response = service.searchanalytics().query(siteUrl=site_url, body=request).execute()\n",
    "# Go down one level in the response object\n",
    "res = response['rows']\n",
    "# Create a DataFrame of the results\n",
    "df = pd.DataFrame.from_dict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the data\n",
    "Clean and format the data into a nice neat Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default the keys/dimensions are in a single column, let's split them out into separate columns.\n",
    "new_cols = df['keys'].astype(str).str.replace(\"[\",\"\").str.replace(\"]\",\"\")\n",
    "new_cols = new_cols.str.split(pat=',',expand=True,n=2)\n",
    "\n",
    "# Give the columsn sensible names\n",
    "new_cols.columns = [\"page\",\"device\",\"keyword\"]\n",
    "\n",
    "# Get rid of quotation marks\n",
    "new_cols['device'] = new_cols['device'].str.replace(\"'\",\"\").str.lower()\n",
    "new_cols['keyword'] = new_cols['keyword'].str.replace(\"'\",\"\")\n",
    "new_cols['page'] = new_cols['page'].str.replace(\"'\",\"\")\n",
    "\n",
    "# Bring back a key from the intial dataframe so we can join\n",
    "new_cols['key'] = df['keys']\n",
    "\n",
    "# Join in the new clean columns to our intiial data\n",
    "result = pd.concat([new_cols,df], axis=1, join='inner')\n",
    "\n",
    "# Drop the key columns\n",
    "result = result.drop([\"key\",\"keys\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a reusable function to do this for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sc_df(site_url,start_date,end_date,start_row):\n",
    "    \"\"\"Grab Search Console data for the specific property and send it to BigQuery.\"\"\"\n",
    "    \n",
    "    request = {\n",
    "      'startDate': start_date,\n",
    "      'endDate': end_date,\n",
    "      'dimensions': [\"page\",\"device\",\"query\"], # uneditable to enforce a nice clean dataframe at the end!\n",
    "      'rowLimit': 25000,\n",
    "      'startRow': start_row\n",
    "       }\n",
    "    \n",
    "    response = service.searchanalytics().query(siteUrl=site_url, body=request).execute()\n",
    "    \n",
    "    if len(response) > 1:\n",
    "    \n",
    "        x = response['rows']\n",
    "\n",
    "        df = pd.DataFrame.from_dict(x)\n",
    "\n",
    "        # By default the keys/dimensions are in a single column, let's split them out into separate columns.\n",
    "        new_cols = df['keys'].astype(str).str.replace(\"[\",\"\").str.replace(\"]\",\"\")\n",
    "        new_cols = new_cols.str.split(pat=',',expand=True,n=2)\n",
    "\n",
    "        # Give the columsn sensible names\n",
    "        new_cols.columns = [\"page\",\"device\",\"keyword\"]\n",
    "\n",
    "        # Get rid of quotation marks\n",
    "        new_cols['device'] = new_cols['device'].str.replace(\"'\",\"\").str.lower().str.trim()\n",
    "        new_cols['keyword'] = new_cols['keyword'].str.replace(\"'\",\"\")str.trim()\n",
    "        new_cols['page'] = new_cols['page'].str.replace(\"'\",\"\")str.trim()\n",
    "\n",
    "        # Bring back a key from the intial dataframe so we can join\n",
    "        new_cols['key'] = df['keys']\n",
    "\n",
    "        # Join in the new clean columns to our intiial data\n",
    "        result = pd.concat([new_cols,df], axis=1, join='inner')\n",
    "\n",
    "        # Drop the key columns\n",
    "        result = result.drop([\"key\",\"keys\"],axis=1)\n",
    "        \n",
    "        # Add a website identifier\n",
    "        result['website'] = site_url\n",
    "        \n",
    "        # establish a BigQuery client\n",
    "        client = bigquery.Client.from_service_account_json(SERVICE_ACCOUNT_FILE)\n",
    "        dataset_id = BQ_DATASET_NAME\n",
    "        table_name = BQ_TABLE_NAME\n",
    "        # create a job config\n",
    "        job_config = bigquery.LoadJobConfig()\n",
    "        # Set the destination table\n",
    "        table_ref = client.dataset(dataset_id).table(table_name)\n",
    "        job_config.destination = table_ref\n",
    "        job_config.write_disposition = 'WRITE_APPEND'\n",
    "\n",
    "        load_job = client.load_table_from_dataframe(result, table_ref, job_config=job_config)\n",
    "        load_job.result()\n",
    "    \n",
    "        return result\n",
    "    else:\n",
    "        print(\"There are no more results to return.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = get_sc_df(\"https://www.mandmdirect.com\",\"2020-01-01\",\"2020-01-01\",100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look through multiple pages of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,100000,25000):\n",
    "    y = get_sc_df(\"https://www.mandmdirect.com\",\"2020-01-01\",\"2020-01-01\",x)\n",
    "    y.info()\n",
    "    if len(y) < 25000:\n",
    "        break\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over multiple properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in PROPERTIES:\n",
    "    for x in range(0,100000,25000):\n",
    "        y = get_sc_df(p,\"2020-01-01\",\"2020-01-01\",x)\n",
    "        if len(y) < 25000:\n",
    "            break\n",
    "        else:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
